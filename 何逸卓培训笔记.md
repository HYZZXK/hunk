# 第二次培训记录
### 10月9日
第一天还没有确定好要选择的方向，选择学习很多项都要用的python,在**官方教程**的帮助下安装过程一切顺利。与想象中不同的是，python居然直接在命令提示符中使用，相较c界面简洁了许多，可代码也要自己单独保存。

### 10月10日
花了三个多小时将python基础学完并完成了已学教程中的所有练习程序（改python路径才可以开.py文件的设定卡了我好久），总之学会了:"%"的使用方法（与C不同啊，print()中用%隔开而不是","）;各种列表的使用(主要是list和tuple的区别),以及新的循环和判断语句（"from..in"和"elif"）;最花时间的莫过于函数的创建，也知道了缩进的重要性(缩进有误函数定义的过程就直接中断了。。。)。

### 10月11日
今天白天空闲时间补作业，晚上听学长报告会（尤其是why学长的报告震撼人心），因此学习内容少，仅把函数创建以及列表进行了进一步的巩固，我发现如果在函数中定义的列表（假定为au）在python界面中au依旧只是毫无意义的字母组合，原因不明。

### 10月12日
* 今天就要开始正式做任务了，说真的，完全不懂深度学习环境和MNSIT数据集是什么(教程也完全没提示)，懒得翻墙(不想花钱)的我就用百度来找资料了。。。
* 先了解了一下MNSIT数据集，这个分为四部分的数据集本质上就是一些经过处理的手写数字图片，我猜机器的学习应该是**以不同数字所占的像素点的巨大差异性和相同数字像素点的相似性来判断测试机图片上的数字吧**。虽然它被称为机器学习的“Hello,world”，但那60000的图片量和28*28的单个图片像素量还是恐怖。教程后面也有很多看不懂的公式和函数，颇有种跳过第二季直接看第三季的感觉。
* 今天虽然只看了一些理论和简介，没有实际动手，但总归找到了需要的资料，双休日努力吧，虽然完全不懂，但可以一边借鉴一边学吧。


### 10月13日
* 图片数据与标签数据相对应，其中图片以([图片序列],[像素点])的张量表示，而标签数据却以“[0,0,0,0,0,0,0,0,0,0]”(数字是几就将第几位的0改为1)的神奇tuple(不知道是不是)来表示其张量的后一部分。
* 学习识别图像就是将特定数字的常有的像素点记为正权值，不应有的计为负
* 神经网络简单分为输入层、计算过程、输出层，可仅输入一层抽象不够，表现力不行，所以要加入隐层进一步抽象，以此来提高成功率?
* 使用**softmax**函数输出某个图片的十个可能输出值的总和为1的十个概率
* 非线性单元可以将无限范围内的值浓缩到[0,1]中(ReLU函数?)
* 使用梯度下降、反向传播等方式调整权重，优化网络
* 学习过程中顺带了解了梯度求导、张量、大小端序、偏导数(∂)、链式法则(d?)、矩阵(二维表格?)、交叉熵等没学过的概念,受时间和精力原因只是了解并未逐个精学
* 本想着照着教程的代码先试验，可在读入的过程就遇到了挫折，于是又查找了读入的方法，不得不说，即使是读入文件，代码也有点长。。。
 
### 10月14日
* 与其说是新的一天不如说是昨夜再续，安装tf出问题后反复安装卸载anancoda三四遍(也试过该地址等方法，但最后结论表明直接删了重置来的最快)，只有一天了还没开始写代码，希望今天能突破吧，边借鉴边学。在过程中顺便体会到了python所具有的安装管理的强大功能并学习了其使用方法。(改着改着conda都不见了)(好吧，py3.7的锅)
* 开始写代码了，虽然有着已完成的代码的案例照着看，但我还是尽量搞懂每一步的含义：

   1.在编写时x(即mnist各图片的数据?)先不输入，以placeholder占位符的形式先给予其在训练中的位置，x以二维张量[None，784]的形式输入，784代表像素点，None代表的第一维度无限，但我认为既然是有限的数据应该可以改为50000或60000。

   2.w为权重，b为偏置量，以Variable的可修改张量表示，它们的值需要学习，因此其初始量可以随意设置。w的格式为[784,10]，不知意思是否为按照784个像素点将数据分为十个类型(?),b的[10]很明显代表十个数，但其意义暂且不明。
   
   3.y就是所得到的概率值，y=w*x+b，以交叉熵来判断模型的成本损失，交叉熵越小越好，在计算交叉熵的过程中，y为机器学习后的预测值，y'为输入的实际值，以batch的方式一次预测多个数据效果更好。以“gradient descent algorithm”的梯度下降算法使变量向成本减小的方向移动，从而降低交叉熵。

   4.训练时每次随机选取100个数据，通过多次的训练以期使用到更多数据子集来提高判断能力

   5.argmax函数能给出对象最高的维上的数值，与equal函数配合就能从标签数据的"1"在哪维得出机器的判断值与实际值是否相等。最后得出的是布尔值，将其转换为浮点数就可以得到结果。
* 代码bug解决：
  
   1.tf.initialize_all_variables的语句已经被淘汰，根据tf的指示应换为tf.global_variables_initializer

   2.TensorFlow版本无法编译使用，即使CPU支持AVX扩展(Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2)，插入一段代码"import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"忽略这个警告

   3.其他诸如语法、没加括号等问题忽略




### 总结：
* 第二次训练实在是让我有些无所适从，毕竟没有guideline之类的东西帮助，一切只能从百度上找。AI对我来说是全新的东西，不仅如此，过程中所利用的python、anaconda、tensorflow等都是完全陌生的事物，在过程中它们都出了一系列问题，解决问题也花了大量时间，但在过程中也窥探出了一些解决思维。
* 自认为学习能力不算顶尖，从零开始自学ai难免走马观花，所用代码可能明天就忘了，在这个过程中学到的python使用知识和高等数学概念相较起来印象还更深刻。
* 一开始还踌躇满志，完全靠自己的能力编出代码，也找到了相关的不用框架的教程，可看了看下面那上百行的于我而言是乱码的代码还是只能叹息。最后还是使用了tensorflow的框架，确实就简单了许多，像反向传播就直接省略了，可于我而言还是利用了太多的陌生函数，python只在课程日简单自学了前几节，有种从小学跳级到高中的既视感。
* 过程中也接收到了些许过时或错误的信息，虽然计科学习提倡亲自动手，但动手前还是要进行判断，同时也要给自己留条后路。
* 这几天大多数时间是在解决电脑对工具的适应性的bug以及了解理论，代码方面不否认借用了网上的，刚做完时有种荒废了时光的感觉，英语高数什么的完全没搞，但我学会的应该是一种隐性的知识，现在看来无法利用，但以后学习时总会较于他人多一种熟悉感和理解能力，既然花了这么多时间，总有收获，也希望能在这条道路上走远点。
* 谨以此总结纪念我与电脑紧紧相依的两天假期。